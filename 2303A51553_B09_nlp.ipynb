{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt2RH1zP8zuRh/LsC9OFcA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A51553/Natural-language-process/blob/main/2303A51553_B09_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w3R1EWKqHi-",
        "outputId": "48e820fc-116d-4922-8c59-c693259b5c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ybbhl8SMqs4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/bbc_news.csv')"
      ],
      "metadata": {
        "id": "G_UEgDHHqSkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['title'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "errJ5JaMq1yE",
        "outputId": "46452092-778d-439c-df4d-8216e3e3fcd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        Ukraine: Angry Zelensky vows to punish Russian...\n",
            "1        War in Ukraine: Taking cover in a town under a...\n",
            "2               Ukraine war 'catastrophic for global food'\n",
            "3        Manchester Arena bombing: Saffie Roussos's par...\n",
            "4        Ukraine conflict: Oil price soars to highest l...\n",
            "                               ...                        \n",
            "42110             Highlights: Wales make history in Dublin\n",
            "42111    Gang jailed over £200m of cocaine in banana boxes\n",
            "42112     Scottish Budget presents huge challenges for SNP\n",
            "42113    Celebrations as Wales make history qualifying ...\n",
            "42114    School tells Muslim girls it’s ‘not safe’ for ...\n",
            "Name: title, Length: 42115, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "uBlfdXhGrlfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load spaCy model"
      ],
      "metadata": {
        "id": "i6aAbGTluNyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "QFs6ggHArrWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "text column e.g 1 row"
      ],
      "metadata": {
        "id": "KjU9-wfLuC-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=df['title'].iloc[0]\n",
        "print(\"Original Text:\\n\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_oKSqu3r2bN",
        "outputId": "1f15e183-f043-4a41-edfc-bb8e6ea5bd13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " Ukraine: Angry Zelensky vows to punish Russian atrocities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Sentence Tokenization:\")\n",
        "doc=nlp(text)\n",
        "for sent in doc.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN0ZzHjer2Tg",
        "outputId": "523aba2e-16c7-41cd-e4c7-ccfd8c3bb1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sentence Tokenization:\n",
            "Ukraine: Angry Zelensky vows to punish Russian atrocities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Word Tokenization:\")\n",
        "for token in doc:\n",
        "  print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T8_8UyOr1u5",
        "outputId": "dc238cc9-b508-471d-e3b8-5838719017b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Word Tokenization:\n",
            "Ukraine\n",
            ":\n",
            "Angry\n",
            "Zelensky\n",
            "vows\n",
            "to\n",
            "punish\n",
            "Russian\n",
            "atrocities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=df['title'].iloc[0:10]\n",
        "print(\"Original Text:\\n\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SHTO4_Ww-fx",
        "outputId": "223bb9f2-21bd-493b-8e30-17b07b97e464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " 0    Ukraine: Angry Zelensky vows to punish Russian...\n",
            "1    War in Ukraine: Taking cover in a town under a...\n",
            "2           Ukraine war 'catastrophic for global food'\n",
            "3    Manchester Arena bombing: Saffie Roussos's par...\n",
            "4    Ukraine conflict: Oil price soars to highest l...\n",
            "5    Ukraine war: PM to hold talks with world leade...\n",
            "6    Ukraine war: UK grants 50 Ukrainian refugee vi...\n",
            "7    TikTok limits services as Netflix pulls out of...\n",
            "8    Covid: Fourth jab for Scotland's vulnerable, a...\n",
            "9        Protests across Russia see thousands detained\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "description=df['description'].iloc[0]\n",
        "print(\"Original Text:\\n\",description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezLLZMkYw-J-",
        "outputId": "0da456eb-8adc-4c5e-c910-086275f2f6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " The Ukrainian president says the country will not forgive or forget those who murder its civilians.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2=\"Wikipedia[c] is a free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and the wiki software MediaWiki. Founded by Jimmy Wales and Larry Sanger in 2001, Wikipedia has been hosted since 2003 by the Wikimedia Foundation, an American nonprofit organization funded mainly by donations from readers.[2] Wikipedia is the largest and most-read reference work in history.[3][4]\""
      ],
      "metadata": {
        "id": "FB26aojNzOuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(text2)"
      ],
      "metadata": {
        "id": "ap_iB99UzxpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in doc.sents:\n",
        "  print(s.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlTASVIsz3rq",
        "outputId": "94abbe43-ce70-4ec9-8717-bb0984cf2d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wikipedia[c] is a free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and the wiki software MediaWiki.\n",
            "Founded by Jimmy Wales and Larry Sanger in 2001, Wikipedia has been hosted since 2003 by the Wikimedia Foundation, an American nonprofit organization funded mainly by donations from readers.[2]\n",
            "Wikipedia is the largest and most-read reference work in history.[3][4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w in doc:\n",
        "  print(w.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8K9X40Sz7-z",
        "outputId": "51dec709-8b37-4317-a865-d8cd4945d017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wikipedia[c\n",
            "]\n",
            "is\n",
            "a\n",
            "free\n",
            "online\n",
            "encyclopedia\n",
            "written\n",
            "and\n",
            "maintained\n",
            "by\n",
            "a\n",
            "community\n",
            "of\n",
            "volunteers\n",
            ",\n",
            "known\n",
            "as\n",
            "Wikipedians\n",
            ",\n",
            "through\n",
            "open\n",
            "collaboration\n",
            "and\n",
            "the\n",
            "wiki\n",
            "software\n",
            "MediaWiki\n",
            ".\n",
            "Founded\n",
            "by\n",
            "Jimmy\n",
            "Wales\n",
            "and\n",
            "Larry\n",
            "Sanger\n",
            "in\n",
            "2001\n",
            ",\n",
            "Wikipedia\n",
            "has\n",
            "been\n",
            "hosted\n",
            "since\n",
            "2003\n",
            "by\n",
            "the\n",
            "Wikimedia\n",
            "Foundation\n",
            ",\n",
            "an\n",
            "American\n",
            "nonprofit\n",
            "organization\n",
            "funded\n",
            "mainly\n",
            "by\n",
            "donations\n",
            "from\n",
            "readers.[2\n",
            "]\n",
            "Wikipedia\n",
            "is\n",
            "the\n",
            "largest\n",
            "and\n",
            "most\n",
            "-\n",
            "read\n",
            "reference\n",
            "work\n",
            "in\n",
            "history.[3][4\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "st=PorterStemmer()\n",
        "for t in doc:\n",
        "  if t.is_alpha:\n",
        "    print(t)\n",
        "    print(t,\"===\",t.lemma_,\"===\",st.stem(t.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoUTvX_B0Pj_",
        "outputId": "4ad07c1a-1dc9-420e-9a4d-7eb1ec5b8b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is\n",
            "is === be === is\n",
            "a\n",
            "a === a === a\n",
            "free\n",
            "free === free === free\n",
            "online\n",
            "online === online === onlin\n",
            "encyclopedia\n",
            "encyclopedia === encyclopedia === encyclopedia\n",
            "written\n",
            "written === write === written\n",
            "and\n",
            "and === and === and\n",
            "maintained\n",
            "maintained === maintain === maintain\n",
            "by\n",
            "by === by === by\n",
            "a\n",
            "a === a === a\n",
            "community\n",
            "community === community === commun\n",
            "of\n",
            "of === of === of\n",
            "volunteers\n",
            "volunteers === volunteer === volunt\n",
            "known\n",
            "known === know === known\n",
            "as\n",
            "as === as === as\n",
            "Wikipedians\n",
            "Wikipedians === Wikipedians === wikipedian\n",
            "through\n",
            "through === through === through\n",
            "open\n",
            "open === open === open\n",
            "collaboration\n",
            "collaboration === collaboration === collabor\n",
            "and\n",
            "and === and === and\n",
            "the\n",
            "the === the === the\n",
            "wiki\n",
            "wiki === wiki === wiki\n",
            "software\n",
            "software === software === softwar\n",
            "MediaWiki\n",
            "MediaWiki === MediaWiki === mediawiki\n",
            "Founded\n",
            "Founded === found === found\n",
            "by\n",
            "by === by === by\n",
            "Jimmy\n",
            "Jimmy === Jimmy === jimmi\n",
            "Wales\n",
            "Wales === Wales === wale\n",
            "and\n",
            "and === and === and\n",
            "Larry\n",
            "Larry === Larry === larri\n",
            "Sanger\n",
            "Sanger === Sanger === sanger\n",
            "in\n",
            "in === in === in\n",
            "Wikipedia\n",
            "Wikipedia === Wikipedia === wikipedia\n",
            "has\n",
            "has === have === ha\n",
            "been\n",
            "been === be === been\n",
            "hosted\n",
            "hosted === host === host\n",
            "since\n",
            "since === since === sinc\n",
            "by\n",
            "by === by === by\n",
            "the\n",
            "the === the === the\n",
            "Wikimedia\n",
            "Wikimedia === Wikimedia === wikimedia\n",
            "Foundation\n",
            "Foundation === Foundation === foundat\n",
            "an\n",
            "an === an === an\n",
            "American\n",
            "American === american === american\n",
            "nonprofit\n",
            "nonprofit === nonprofit === nonprofit\n",
            "organization\n",
            "organization === organization === organ\n",
            "funded\n",
            "funded === fund === fund\n",
            "mainly\n",
            "mainly === mainly === mainli\n",
            "by\n",
            "by === by === by\n",
            "donations\n",
            "donations === donation === donat\n",
            "from\n",
            "from === from === from\n",
            "Wikipedia\n",
            "Wikipedia === Wikipedia === wikipedia\n",
            "is\n",
            "is === be === is\n",
            "the\n",
            "the === the === the\n",
            "largest\n",
            "largest === large === largest\n",
            "and\n",
            "and === and === and\n",
            "most\n",
            "most === most === most\n",
            "read\n",
            "read === read === read\n",
            "reference\n",
            "reference === reference === refer\n",
            "work\n",
            "work === work === work\n",
            "in\n",
            "in === in === in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 10):\n",
        "    title_text = df['title'].iloc[i]\n",
        "    description_text = df['description'].iloc[i]\n",
        "\n",
        "    print(\"Title:\")\n",
        "    doc_title = nlp(title_text)\n",
        "    for t in doc_title:\n",
        "        if t.is_alpha:\n",
        "            print(t, \"==\", t.lemma_, \"===\", st.stem(t.text))\n",
        "\n",
        "    print(\"\\nDescription:\")\n",
        "    doc_desc = nlp(description_text)\n",
        "    for t in doc_desc:\n",
        "        if t.is_alpha:\n",
        "            print(t, \"==\", t.lemma_, \"===\", st.stem(t.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZNpUeD-3Bu8",
        "outputId": "3cebf42f-f4c1-4b60-9b32-809a4fe32892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title:\n",
            "Ukraine == Ukraine === ukrain\n",
            "Angry == angry === angri\n",
            "Zelensky == Zelensky === zelenski\n",
            "vows == vow === vow\n",
            "to == to === to\n",
            "punish == punish === punish\n",
            "Russian == russian === russian\n",
            "atrocities == atrocity === atroc\n",
            "\n",
            "Description:\n",
            "The == the === the\n",
            "Ukrainian == ukrainian === ukrainian\n",
            "president == president === presid\n",
            "says == say === say\n",
            "the == the === the\n",
            "country == country === countri\n",
            "will == will === will\n",
            "not == not === not\n",
            "forgive == forgive === forgiv\n",
            "or == or === or\n",
            "forget == forget === forget\n",
            "those == those === those\n",
            "who == who === who\n",
            "murder == murder === murder\n",
            "its == its === it\n",
            "civilians == civilian === civilian\n",
            "Title:\n",
            "War == War === war\n",
            "in == in === in\n",
            "Ukraine == Ukraine === ukrain\n",
            "Taking == take === take\n",
            "cover == cover === cover\n",
            "in == in === in\n",
            "a == a === a\n",
            "town == town === town\n",
            "under == under === under\n",
            "attack == attack === attack\n",
            "\n",
            "Description:\n",
            "Jeremy == Jeremy === jeremi\n",
            "Bowen == Bowen === bowen\n",
            "was == be === wa\n",
            "on == on === on\n",
            "the == the === the\n",
            "frontline == frontline === frontlin\n",
            "in == in === in\n",
            "Irpin == Irpin === irpin\n",
            "as == as === as\n",
            "residents == resident === resid\n",
            "came == come === came\n",
            "under == under === under\n",
            "Russian == russian === russian\n",
            "fire == fire === fire\n",
            "while == while === while\n",
            "trying == try === tri\n",
            "to == to === to\n",
            "flee == flee === flee\n",
            "Title:\n",
            "Ukraine == Ukraine === ukrain\n",
            "war == war === war\n",
            "catastrophic == catastrophic === catastroph\n",
            "for == for === for\n",
            "global == global === global\n",
            "food == food === food\n",
            "\n",
            "Description:\n",
            "One == one === one\n",
            "of == of === of\n",
            "the == the === the\n",
            "world == world === world\n",
            "biggest == big === biggest\n",
            "fertiliser == fertiliser === fertilis\n",
            "firms == firm === firm\n",
            "says == say === say\n",
            "the == the === the\n",
            "conflict == conflict === conflict\n",
            "could == could === could\n",
            "deliver == deliver === deliv\n",
            "a == a === a\n",
            "shock == shock === shock\n",
            "to == to === to\n",
            "food == food === food\n",
            "supplies == supply === suppli\n",
            "Title:\n",
            "Manchester == Manchester === manchest\n",
            "Arena == Arena === arena\n",
            "bombing == bombing === bomb\n",
            "Saffie == Saffie === saffi\n",
            "Roussos == Roussos === rousso\n",
            "parents == parent === parent\n",
            "on == on === on\n",
            "hearing == hear === hear\n",
            "the == the === the\n",
            "truth == truth === truth\n",
            "\n",
            "Description:\n",
            "The == the === the\n",
            "parents == parent === parent\n",
            "of == of === of\n",
            "the == the === the\n",
            "Manchester == Manchester === manchest\n",
            "Arena == Arena === arena\n",
            "bombing == bombing === bomb\n",
            "youngest == young === youngest\n",
            "victim == victim === victim\n",
            "speak == speak === speak\n",
            "about == about === about\n",
            "their == their === their\n",
            "life == life === life\n",
            "since == since === sinc\n",
            "she == she === she\n",
            "died == die === die\n",
            "Title:\n",
            "Ukraine == Ukraine === ukrain\n",
            "conflict == conflict === conflict\n",
            "Oil == oil === oil\n",
            "price == price === price\n",
            "soars == soar === soar\n",
            "to == to === to\n",
            "highest == high === highest\n",
            "level == level === level\n",
            "since == since === sinc\n",
            "\n",
            "Description:\n",
            "Consumers == consumer === consum\n",
            "are == be === are\n",
            "feeling == feel === feel\n",
            "the == the === the\n",
            "impact == impact === impact\n",
            "of == of === of\n",
            "higher == high === higher\n",
            "energy == energy === energi\n",
            "costs == cost === cost\n",
            "as == as === as\n",
            "fuel == fuel === fuel\n",
            "prices == price === price\n",
            "and == and === and\n",
            "household == household === household\n",
            "bills == bill === bill\n",
            "jump == jump === jump\n",
            "Title:\n",
            "Ukraine == Ukraine === ukrain\n",
            "war == war === war\n",
            "PM == pm === pm\n",
            "to == to === to\n",
            "hold == hold === hold\n",
            "talks == talk === talk\n",
            "with == with === with\n",
            "world == world === world\n",
            "leaders == leader === leader\n",
            "on == on === on\n",
            "further == further === further\n",
            "sanctions == sanction === sanction\n",
            "\n",
            "Description:\n",
            "Boris == Boris === bori\n",
            "Johnson == Johnson === johnson\n",
            "is == be === is\n",
            "to == to === to\n",
            "meet == meet === meet\n",
            "the == the === the\n",
            "Canadian == canadian === canadian\n",
            "and == and === and\n",
            "Dutch == dutch === dutch\n",
            "PMs == pm === pm\n",
            "as == as === as\n",
            "MPs == mp === mp\n",
            "debate == debate === debat\n",
            "new == new === new\n",
            "laws == law === law\n",
            "targeting == target === target\n",
            "oligarchs == oligarch === oligarch\n",
            "Title:\n",
            "Ukraine == Ukraine === ukrain\n",
            "war == war === war\n",
            "UK == UK === uk\n",
            "grants == grant === grant\n",
            "Ukrainian == ukrainian === ukrainian\n",
            "refugee == refugee === refuge\n",
            "visas == visa === visa\n",
            "so == so === so\n",
            "far == far === far\n",
            "\n",
            "Description:\n",
            "The == the === the\n",
            "home == home === home\n",
            "secretary == secretary === secretari\n",
            "says == say === say\n",
            "she == she === she\n",
            "is == be === is\n",
            "surging == surge === surg\n",
            "capacity == capacity === capac\n",
            "as == as === as\n",
            "about == about === about\n",
            "of == of === of\n",
            "applications == application === applic\n",
            "are == be === are\n",
            "granted == grant === grant\n",
            "Title:\n",
            "TikTok == tiktok === tiktok\n",
            "limits == limit === limit\n",
            "services == service === servic\n",
            "as == as === as\n",
            "Netflix == Netflix === netflix\n",
            "pulls == pull === pull\n",
            "out == out === out\n",
            "of == of === of\n",
            "Russia == Russia === russia\n",
            "\n",
            "Description:\n",
            "TikTok == tiktok === tiktok\n",
            "suspends == suspend === suspend\n",
            "live == live === live\n",
            "streaming == streaming === stream\n",
            "and == and === and\n",
            "new == new === new\n",
            "content == content === content\n",
            "from == from === from\n",
            "its == its === it\n",
            "platform == platform === platform\n",
            "while == while === while\n",
            "Russians == Russians === russian\n",
            "can == can === can\n",
            "no == no === no\n",
            "longer == long === longer\n",
            "access == access === access\n",
            "Netflix == Netflix === netflix\n",
            "Title:\n",
            "Covid == covid === covid\n",
            "Fourth == fourth === fourth\n",
            "jab == jab === jab\n",
            "for == for === for\n",
            "Scotland == Scotland === scotland\n",
            "vulnerable == vulnerable === vulner\n",
            "and == and === and\n",
            "testing == test === test\n",
            "wind == wind === wind\n",
            "down == down === down\n",
            "fears == fear === fear\n",
            "in == in === in\n",
            "Wales == Wales === wale\n",
            "\n",
            "Description:\n",
            "Five == five === five\n",
            "things == thing === thing\n",
            "you == you === you\n",
            "need == need === need\n",
            "to == to === to\n",
            "know == know === know\n",
            "about == about === about\n",
            "the == the === the\n",
            "coronavirus == coronavirus === coronaviru\n",
            "pandemic == pandemic === pandem\n",
            "this == this === thi\n",
            "Monday == Monday === monday\n",
            "morning == morning === morn\n",
            "Title:\n",
            "Protests == protest === protest\n",
            "across == across === across\n",
            "Russia == Russia === russia\n",
            "see == see === see\n",
            "thousands == thousand === thousand\n",
            "detained == detain === detain\n",
            "\n",
            "Description:\n",
            "People == People === peopl\n",
            "have == have === have\n",
            "been == be === been\n",
            "held == hold === held\n",
            "in == in === in\n",
            "cities == city === citi\n",
            "from == from === from\n",
            "St == St === st\n",
            "Petersburg == Petersburg === petersburg\n",
            "in == in === in\n",
            "the == the === the\n",
            "west == west === west\n",
            "to == to === to\n",
            "Vladivostok == Vladivostok === vladivostok\n",
            "in == in === in\n",
            "the == the === the\n",
            "east == east === east\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "title = \"Understanding how natural language processing works\"\n",
        "doc_title = nlp(title)\n",
        "for t in doc_title:\n",
        "    if t.is_alpha:\n",
        "        print(f\"{t.text} === {t.lemma_} === {st.stem(t.text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Kr3Lnw3E8t",
        "outputId": "d7fa69ac-187a-4f86-ed19-3d23f540eb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Understanding === understand === understand\n",
            "how === how === how\n",
            "natural === natural === natur\n",
            "language === language === languag\n",
            "processing === processing === process\n",
            "works === work === work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "doc_description = nlp(description)\n",
        "for t in doc_description:\n",
        "    if t.is_alpha:\n",
        "        print(f\"{t.text} === {t.lemma_} === {st.stem(t.text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJcepUt77Ky_",
        "outputId": "c2cc726a-8120-4220-ebf3-2166fb82a64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The === the === the\n",
            "Ukrainian === ukrainian === ukrainian\n",
            "president === president === presid\n",
            "says === say === say\n",
            "the === the === the\n",
            "country === country === countri\n",
            "will === will === will\n",
            "not === not === not\n",
            "forgive === forgive === forgiv\n",
            "or === or === or\n",
            "forget === forget === forget\n",
            "those === those === those\n",
            "who === who === who\n",
            "murder === murder === murder\n",
            "its === its === it\n",
            "civilians === civilian === civilian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from nltk.stem import PorterStemmer\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "st = PorterStemmer()\n",
        "word = \"changing\"\n",
        "doc = nlp(word)\n",
        "for t in doc:\n",
        "    if t.is_alpha:\n",
        "        print(\"Original word:\", t.text)\n",
        "        print(\"Lemma:\", t.lemma_)\n",
        "        print(\"Stem:\", st.stem(t.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocVgAicG7OvQ",
        "outputId": "b5d146d9-3410-44cd-c2c6-98e49c073139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original word: changing\n",
            "Lemma: change\n",
            "Stem: chang\n"
          ]
        }
      ]
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A51553/Natural-language-process/blob/main/Copy_of_2303A51553_b09_nlp6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTVom8Xs4APj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgSZkD_G4XQx"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2eqSgbdE7xTh",
        "outputId": "00c734eb-0a25-4a15-951a-6ae33b775366"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11370,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3282,\n        \"min\": 0,\n        \"max\": 11369,\n        \"num_unique_values\": 11370,\n        \"samples\": [\n          3495,\n          5461,\n          9794\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 219,\n        \"samples\": [\n          \"panicking\",\n          \"evacuate\",\n          \"wreck\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4504,\n        \"samples\": [\n          \"mercado\",\n          \"pittsburgh\",\n          \"Swimming places\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11223,\n        \"samples\": [\n          \"Stretcher \\ud83d\\ude02\",\n          \"Blazing Saddles' at 45: The Movie That Couldn't Get Made Today https://t.co/Jmf8s1VZtJ #NewsandPolitics via\",\n          \"Huh. I guess people are not suffering so it cant be called a tragedy. Youre completely blinded by your o\\u2026 https://t.co/3es4YfcAhz\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-24da2938-4f7e-4295-bb78-cf5a07dc0d05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>New York City</td>\n",
              "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>Morgantown, WV</td>\n",
              "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24da2938-4f7e-4295-bb78-cf5a07dc0d05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24da2938-4f7e-4295-bb78-cf5a07dc0d05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24da2938-4f7e-4295-bb78-cf5a07dc0d05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2745076c-a456-4e7e-be4e-3389d7fca7ac\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2745076c-a456-4e7e-be4e-3389d7fca7ac')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2745076c-a456-4e7e-be4e-3389d7fca7ac button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   id keyword        location  \\\n",
              "0   0  ablaze             NaN   \n",
              "1   1  ablaze             NaN   \n",
              "2   2  ablaze   New York City   \n",
              "3   3  ablaze  Morgantown, WV   \n",
              "4   4  ablaze             NaN   \n",
              "\n",
              "                                                text  target  \n",
              "0  Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
              "1  Telangana: Section 144 has been imposed in Bha...       1  \n",
              "2  Arsonist sets cars ablaze at dealership https:...       1  \n",
              "3  Arsonist sets cars ablaze at dealership https:...       1  \n",
              "4  \"Lord Jesus, your love brings freedom and pard...       0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7JBrbeV7dR3",
        "outputId": "c65ba711-8c72-4598-ca65-f4d3422d72bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          id  keyword                 location  \\\n",
            "0          0   ablaze                      NaN   \n",
            "1          1   ablaze                      NaN   \n",
            "2          2   ablaze            New York City   \n",
            "3          3   ablaze           Morgantown, WV   \n",
            "4          4   ablaze                      NaN   \n",
            "...      ...      ...                      ...   \n",
            "11365  11365  wrecked  Blue State in a red sea   \n",
            "11366  11366  wrecked               arohaonces   \n",
            "11367  11367  wrecked                       üáµüá≠   \n",
            "11368  11368  wrecked           auroraborealis   \n",
            "11369  11369  wrecked                      NaN   \n",
            "\n",
            "                                                    text  target  \\\n",
            "0      Communal violence in Bhainsa, Telangana. \"Ston...       1   \n",
            "1      Telangana: Section 144 has been imposed in Bha...       1   \n",
            "2      Arsonist sets cars ablaze at dealership https:...       1   \n",
            "3      Arsonist sets cars ablaze at dealership https:...       1   \n",
            "4      \"Lord Jesus, your love brings freedom and pard...       0   \n",
            "...                                                  ...     ...   \n",
            "11365  Media should have warned us well in advance. T...       0   \n",
            "11366  i feel directly attacked üíÄ i consider moonbin ...       0   \n",
            "11367  i feel directly attacked üíÄ i consider moonbin ...       0   \n",
            "11368  ok who remember \"outcast\" nd the \"dora\" au?? T...       0   \n",
            "11369     Jake Corway wrecked while running 14th at IRP.       1   \n",
            "\n",
            "                                            cleaned_text  \n",
            "0      communal violence bhainsa telangana stone pelt...  \n",
            "1      telangana section 144 imposed bhainsa january ...  \n",
            "2      arsonist set car ablaze dealership httpstcogoq...  \n",
            "3      arsonist set car ablaze dealership httpstco0gl...  \n",
            "4      lord jesus love brings freedom pardon fill hol...  \n",
            "...                                                  ...  \n",
            "11365  medium warned u well advance wrecked whole nig...  \n",
            "11366  feel directly attacked consider moonbin amp ji...  \n",
            "11367  feel directly attacked consider moonbin amp ji...  \n",
            "11368  ok remember outcast nd dora au au wrecked nerv...  \n",
            "11369               jake corway wrecked running 14th irp  \n",
            "\n",
            "[11370 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "import nltk\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def preprocess_text(text):\n",
        "    text=text.lower()\n",
        "    text=text.translate(str.maketrans('', '', string.punctuation)) # Remove punctuation\n",
        "    text=re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    tokens=word_tokenize(text)#tokenization\n",
        "    stop_words=set(stopwords.words('english'))#stop words\n",
        "    tokens=[word for word in tokens if word not in stop_words]\n",
        "    tokens=[lemmatizer.lemmatize(word) for word in tokens] # Lemmatization\n",
        "    return \" \".join(tokens)\n",
        "df[\"cleaned_text\"]=df[\"text\"].astype(str).apply(preprocess_text)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAMyXGbi9wr6"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer=TfidfVectorizer(ngram_range=(1,2),max_features=20000)\n",
        "X=vectorizer.fit_transform(df[\"cleaned_text\"])\n",
        "y=df[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-hY-43b4E-p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Embedding,LSTM,Dropout,Conv1D,GlobalMaxPooling1D,Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGVfXq079nG",
        "outputId": "5e9c7112-f86a-48f6-c0dc-1a920710b4aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7989 - loss: 0.5269 - val_accuracy: 0.8835 - val_loss: 0.2942\n",
            "Epoch 2/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.2115 - val_accuracy: 0.9019 - val_loss: 0.2689\n",
            "Epoch 3/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9700 - loss: 0.0905 - val_accuracy: 0.8975 - val_loss: 0.3125\n",
            "Epoch 4/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0431 - val_accuracy: 0.8980 - val_loss: 0.3705\n",
            "Epoch 5/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0191 - val_accuracy: 0.8962 - val_loss: 0.4156\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d185e2c6f30>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "mlp=Sequential([\n",
        "    Dense(128,activation=\"relu\",input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64,activation=\"relu\"),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "mlp.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "mlp.fit(X_train.toarray(),y_train,validation_data=(X_test.toarray(),y_test),epochs=5,batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2vnq7ThDiGS",
        "outputId": "92d1226b-f166-4d3f-a726-2355a9e5ed57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9953 - loss: 0.0155 - val_accuracy: 0.8967 - val_loss: 0.5200\n",
            "Epoch 2/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0113 - val_accuracy: 0.8901 - val_loss: 0.5458\n",
            "Epoch 3/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 0.0078 - val_accuracy: 0.8958 - val_loss: 0.5810\n",
            "Epoch 4/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0091 - val_accuracy: 0.8936 - val_loss: 0.5808\n",
            "Epoch 5/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.8914 - val_loss: 0.5717\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d17ee7066f0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "mlp.fit(X_train.toarray(),y_train,validation_data=(X_test.toarray(),y_test),epochs=5,batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgXYnceMDldC",
        "outputId": "be25f571-32f5-4ace-87ff-28f2f53217e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m72/72\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8974 - loss: 0.5387\n",
            "Test Loss: 0.5717\n",
            "Test Accuracy: 0.8914\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy=mlp.evaluate(X_test.toarray(),y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrmcfCc6HoCi",
        "outputId": "65efc53c-101a-4b93-a908-5b9d3511f0df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.8026 - loss: 0.4926 - val_accuracy: 0.8984 - val_loss: 0.2700\n",
            "Epoch 2/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9314 - loss: 0.1876 - val_accuracy: 0.9046 - val_loss: 0.2562\n",
            "Epoch 3/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9774 - loss: 0.0774 - val_accuracy: 0.8936 - val_loss: 0.3201\n",
            "Epoch 4/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0364 - val_accuracy: 0.8962 - val_loss: 0.3840\n",
            "Epoch 5/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0157 - val_accuracy: 0.8958 - val_loss: 0.4185\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d17ec2b6cf0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(df[\"cleaned_text\"])\n",
        "X_seq = tokenizer.texts_to_sequences(df[\"cleaned_text\"])\n",
        "X_pad = pad_sequences(X_seq, maxlen=100)\n",
        "\n",
        "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "cnn = Sequential([\n",
        "    Embedding(vocab_size, 128, input_length=100),\n",
        "    Conv1D(128, 5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "cnn.fit(X_train_seq, y_train_seq, validation_data=(X_test_seq, y_test_seq), epochs=5, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bj7NSE8HAYs",
        "outputId": "93426ce3-455e-4ea5-8148-9b2ab7f39bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 474ms/step - accuracy: 0.8105 - loss: 0.4936 - val_accuracy: 0.8259 - val_loss: 0.4646\n",
            "Epoch 2/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 385ms/step - accuracy: 0.8045 - loss: 0.4981 - val_accuracy: 0.8259 - val_loss: 0.4619\n",
            "Epoch 3/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 391ms/step - accuracy: 0.8159 - loss: 0.4796 - val_accuracy: 0.8259 - val_loss: 0.4653\n",
            "Epoch 4/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 390ms/step - accuracy: 0.8185 - loss: 0.4792 - val_accuracy: 0.8259 - val_loss: 0.4617\n",
            "Epoch 5/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 395ms/step - accuracy: 0.8117 - loss: 0.4886 - val_accuracy: 0.8259 - val_loss: 0.4730\n"
          ]
        }
      ],
      "source": [
        "cnn.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "cnn.fit(X_train.toarray(),y_train,validation_data=(X_test.toarray(),y_test),epochs=5,batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39hU5DUhD6-0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer=Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(df[\"cleaned_text\"])\n",
        "X_seq=tokenizer.texts_to_sequences(df[\"cleaned_text\"])\n",
        "X_pad=pad_sequences(X_seq,maxlen=100)\n",
        "\n",
        "X_train_seq,X_test_seq,y_train_seq,y_test_seq=train_test_split(X_pad,y,test_size=0.2,random_state=42)\n",
        "\n",
        "vocab_size=len(tokenizer.word_index)+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "INN2kqTqD7rS",
        "outputId": "cc159df3-969c-458a-df56-d5d1b848c881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.8101 - loss: 0.4698 - val_accuracy: 0.9046 - val_loss: 0.2606\n",
            "Epoch 2/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9318 - loss: 0.1967 - val_accuracy: 0.8826 - val_loss: 0.2875\n",
            "Epoch 3/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9643 - loss: 0.1134 - val_accuracy: 0.8949 - val_loss: 0.3002\n",
            "Epoch 4/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9824 - loss: 0.0603 - val_accuracy: 0.8905 - val_loss: 0.3302\n",
            "Epoch 5/5\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9885 - loss: 0.0398 - val_accuracy: 0.8641 - val_loss: 0.4947\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d17e029e1b0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm=Sequential([\n",
        "    Embedding(vocab_size,128,input_length=100),\n",
        "    Bidirectional(LSTM(64,return_sequences=False)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "lstm.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "lstm.fit(X_train_seq,y_train_seq,validation_data=(X_test_seq,y_test_seq),epochs=5,batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "# Make predictions\n",
        "mlp_y_pred = (mlp.predict(X_test.toarray()) > 0.5).astype(\"int32\")\n",
        "cnn_y_pred = (cnn.predict(X_test_seq) > 0.5).astype(\"int32\")\n",
        "lstm_y_pred = (lstm.predict(X_test_seq) > 0.5).astype(\"int32\")\n",
        "# Generate and print classification reports\n",
        "print(\"MLP Model Classification Report:\")\n",
        "print(classification_report(y_test, mlp_y_pred))\n",
        "print(\"\\nCNN Model Classification Report:\")\n",
        "print(classification_report(y_test, cnn_y_pred))\n",
        "print(\"\\nBi-LSTM Model Classification Report:\")\n",
        "print(classification_report(y_test, lstm_y_pred))\n",
        "# Generate and print confusion matrices\n",
        "print(\"MLP Model Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, mlp_y_pred))\n",
        "print(\"\\nCNN Model Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, cnn_y_pred))\n",
        "print(\"\\nBi-LSTM Model Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, lstm_y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ00KIKGkwIj",
        "outputId": "2ea0a232-5a87-40ca-d232-8366d52d7af9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m72/72\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "MLP Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93      1878\n",
            "           1       0.71      0.64      0.67       396\n",
            "\n",
            "    accuracy                           0.89      2274\n",
            "   macro avg       0.82      0.79      0.80      2274\n",
            "weighted avg       0.89      0.89      0.89      2274\n",
            "\n",
            "\n",
            "CNN Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93      1878\n",
            "           1       0.64      0.72      0.68       396\n",
            "\n",
            "    accuracy                           0.88      2274\n",
            "   macro avg       0.79      0.82      0.80      2274\n",
            "weighted avg       0.89      0.88      0.88      2274\n",
            "\n",
            "\n",
            "Bi-LSTM Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.92      1878\n",
            "           1       0.59      0.75      0.66       396\n",
            "\n",
            "    accuracy                           0.86      2274\n",
            "   macro avg       0.76      0.82      0.79      2274\n",
            "weighted avg       0.88      0.86      0.87      2274\n",
            "\n",
            "MLP Model Confusion Matrix:\n",
            "[[1772  106]\n",
            " [ 141  255]]\n",
            "\n",
            "CNN Model Confusion Matrix:\n",
            "[[1717  161]\n",
            " [ 111  285]]\n",
            "\n",
            "Bi-LSTM Model Confusion Matrix:\n",
            "[[1668  210]\n",
            " [  99  297]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_y_pred = lr_model.predict(X_test)\n",
        "print(\"Logistic Regression Model Classification Report:\")\n",
        "print(classification_report(y_test, lr_y_pred))\n",
        "print(\"\\nLogistic Regression Model Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, lr_y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDtSH4z5lIGa",
        "outputId": "a2fe075a-d8c1-4451-831f-2182fda62dd7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.99      0.93      1878\n",
            "           1       0.90      0.29      0.44       396\n",
            "\n",
            "    accuracy                           0.87      2274\n",
            "   macro avg       0.88      0.64      0.68      2274\n",
            "weighted avg       0.87      0.87      0.84      2274\n",
            "\n",
            "\n",
            "Logistic Regression Model Confusion Matrix:\n",
            "[[1865   13]\n",
            " [ 280  116]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_y_pred = svm_model.predict(X_test)\n",
        "print(\"SVM Model Classification Report:\")\n",
        "print(classification_report(y_test, svm_y_pred))\n",
        "print(\"\\nSVM Model Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, svm_y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efiinJgNlNUv",
        "outputId": "86333e24-45b1-434b-ad25-481971841a5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94      1878\n",
            "           1       0.93      0.43      0.59       396\n",
            "\n",
            "    accuracy                           0.89      2274\n",
            "   macro avg       0.91      0.71      0.76      2274\n",
            "weighted avg       0.90      0.89      0.88      2274\n",
            "\n",
            "\n",
            "SVM Model Confusion Matrix:\n",
            "[[1865   13]\n",
            " [ 226  170]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP1Im5/0i4eTcs4SUjv0rNt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}